#SENTENCE_ID	SENTENCE --- TERMS ARE MARKED WITH A TAG -- AN ANNOTATED TERM PER SENTENCE -- ONLY FOR VALID AND TECHNOLOGY TERMS
5	PartslD <term id="65781" ann="1">system architecture</term>
6	The <term id="5506" ann="2">parser</term> scans a user utterance and returns , as output , a list of semantic tuples associated with each keyword\/phrase contained in the utterance .
6	The parser scans a <term id="811" ann="1">user</term> utterance and returns , as output , a list of semantic tuples associated with each keyword\/phrase contained in the utterance .
6	The parser scans a <term id="49149" ann="1">user utterance</term> and returns , as output , a list of semantic tuples associated with each keyword\/phrase contained in the utterance .
6	The parser scans a user <term id="5003" ann="1">utterance</term> and returns , as output , a list of semantic tuples associated with each keyword\/phrase contained in the utterance .
6	The parser scans a user utterance and returns , as output , a list of <term id="7368" ann="1">semantic</term> tuples associated with each keyword\/phrase contained in the utterance .
6	The parser scans a user utterance and returns , as output , a list of semantic tuples associated with each keyword\/phrase contained in the <term id="5003" ann="1">utterance</term> .
7	As mentioned earlier , some customer service centers now allow users to say either the option number or a <term id="12935" ann="1">keyword</term> from a list of options\/descriptions .
9	Listed below are the details of the <term id="453" ann="2">algorithm</term> : 1 -RRB- The algorithm first concatenates the words of the user utterance into one long string .
9	Listed below are the details of the algorithm : 1 -RRB- The <term id="453" ann="2">algorithm</term> first concatenates the words of the user utterance into one long string .
9	Listed below are the details of the algorithm : 1 -RRB- The algorithm first concatenates the <term id="13899" ann="1">words</term> of the user utterance into one long string .
9	Listed below are the details of the algorithm : 1 -RRB- The algorithm first concatenates the words of the <term id="811" ann="1">user</term> utterance into one long string .
9	Listed below are the details of the algorithm : 1 -RRB- The algorithm first concatenates the words of the <term id="49149" ann="1">user utterance</term> into one long string .
9	Listed below are the details of the algorithm : 1 -RRB- The algorithm first concatenates the words of the user <term id="5003" ann="1">utterance</term> into one long string .
18	If the speech option for the system is turned on , the speech-based output is generated using Lernout fiand Hauspie 's RealSpeak <term id="61721" ann="2">text-to-speech</term> system .
18	If the speech option for the system is turned on , the speech-based output is generated using Lernout fiand Hauspie 's RealSpeak <term id="61722" ann="2">text-to-speech system</term> .
20	It should be noted that the set of domain-specific keywords and phrases was provided to the <term id="9254" ann="2">speech recognition</term> system as a text document .
20	It should be noted that the set of domain-specific keywords and phrases was provided to the <term id="60256" ann="2">speech recognition system</term> as a text document .
20	It should be noted that the set of domain-specific keywords and phrases was provided to the speech <term id="1413" ann="2">recognition</term> system as a text document .
20	It should be noted that the set of domain-specific keywords and phrases was provided to the speech <term id="28960" ann="2">recognition system</term> as a text document .
20	It should be noted that the set of domain-specific keywords and phrases was provided to the speech recognition system as a <term id="132" ann="1">text</term> document .
20	It should be noted that the set of domain-specific keywords and phrases was provided to the speech recognition system as a text <term id="349" ann="1">document</term> .
30	Since customer service centers are meant to be used by a variety of users , we needed a userindependent <term id="9254" ann="2">speech recognition</term> system .
30	Since customer service centers are meant to be used by a variety of users , we needed a userindependent <term id="60256" ann="2">speech recognition system</term> .
30	Since customer service centers are meant to be used by a variety of users , we needed a userindependent speech <term id="1413" ann="2">recognition</term> system .
30	Since customer service centers are meant to be used by a variety of users , we needed a userindependent speech <term id="28960" ann="2">recognition system</term> .
57	The <term id="2055" ann="1">lexicon</term> , in addition to providing domain-dependent keywords and phrases to the parser , also provides the semantic knowledge associated with each keyword and phrase .
57	The lexicon , in addition to providing domain-dependent keywords and phrases to the <term id="5506" ann="2">parser</term> , also provides the semantic knowledge associated with each keyword and phrase .
57	The lexicon , in addition to providing domain-dependent keywords and phrases to the parser , also provides the <term id="7368" ann="1">semantic</term> knowledge associated with each keyword and phrase .
57	The lexicon , in addition to providing domain-dependent keywords and phrases to the parser , also provides the <term id="43191" ann="1">semantic knowledge</term> associated with each keyword and phrase .
57	The lexicon , in addition to providing domain-dependent keywords and phrases to the parser , also provides the semantic <term id="378" ann="1">knowledge</term> associated with each keyword and phrase .
57	The lexicon , in addition to providing domain-dependent keywords and phrases to the parser , also provides the semantic knowledge associated with each <term id="12935" ann="1">keyword</term> and phrase .
57	The lexicon , in addition to providing domain-dependent keywords and phrases to the parser , also provides the semantic knowledge associated with each keyword and <term id="196" ann="1">phrase</term> .
60	This paper describes a system that provides customer service by allowing users to retrieve <term id="1248" ann="2">identification</term> numbers of parts for medical systems using spoken natural language dialogue .
60	This paper describes a system that provides customer service by allowing users to retrieve identification numbers of parts for medical systems using <term id="127793" ann="1">spoken natural language</term> dialogue .
60	This paper describes a system that provides customer service by allowing users to retrieve identification numbers of parts for medical systems using spoken <term id="447" ann="1">natural language</term> dialogue .
60	This paper describes a system that provides customer service by allowing users to retrieve identification numbers of parts for medical systems using spoken <term id="148342" ann="2">natural language dialogue</term> .
61	The paper also presents an evaluation of the system which shows that the system successfully retrieves the <term id="1248" ann="2">identification</term> numbers of approximately 80 % of the parts .
63	The DM navigates the space of possibilities by first analyzing the intersection of the sets of parts corresponding to the description <term id="13899" ann="1">words</term> uttered by the user .
63	The DM navigates the space of possibilities by first analyzing the intersection of the sets of parts corresponding to the description words uttered by the <term id="811" ann="1">user</term> .
64	While we have not evaluated this <term id="2629" ann="1">substring</term> matching algorithm independently , a brief evaluation in the context of the system resulted in about 90 % accuracy .
64	While we have not evaluated this substring <term id="1795" ann="2">matching</term> algorithm independently , a brief evaluation in the context of the system resulted in about 90 % accuracy .
64	While we have not evaluated this substring <term id="18720" ann="2">matching algorithm</term> independently , a brief evaluation in the context of the system resulted in about 90 % accuracy .
64	While we have not evaluated this substring matching <term id="453" ann="2">algorithm</term> independently , a brief evaluation in the context of the system resulted in about 90 % accuracy .
67	Therefore , the <term id="515811" ann="2">context-based parser</term> ranks the input received from the user using a sub-string matching algorithm that uses character-based unigram and bigram counts -LRB- details are provided in the next section -RRB- .
67	Therefore , the context-based <term id="5506" ann="2">parser</term> ranks the input received from the user using a sub-string matching algorithm that uses character-based unigram and bigram counts -LRB- details are provided in the next section -RRB- .
67	Therefore , the context-based parser ranks the input received from the <term id="811" ann="1">user</term> using a sub-string matching algorithm that uses character-based unigram and bigram counts -LRB- details are provided in the next section -RRB- .
67	Therefore , the context-based parser ranks the input received from the user using a <term id="459677" ann="2">sub-string matching</term> algorithm that uses character-based unigram and bigram counts -LRB- details are provided in the next section -RRB- .
67	Therefore , the context-based parser ranks the input received from the user using a sub-string <term id="1795" ann="2">matching</term> algorithm that uses character-based unigram and bigram counts -LRB- details are provided in the next section -RRB- .
67	Therefore , the context-based parser ranks the input received from the user using a sub-string <term id="18720" ann="2">matching algorithm</term> that uses character-based unigram and bigram counts -LRB- details are provided in the next section -RRB- .
67	Therefore , the context-based parser ranks the input received from the user using a sub-string matching <term id="453" ann="2">algorithm</term> that uses character-based unigram and bigram counts -LRB- details are provided in the next section -RRB- .
67	Therefore , the context-based parser ranks the input received from the user using a sub-string matching algorithm that uses character-based <term id="40448" ann="1">unigram</term> and bigram counts -LRB- details are provided in the next section -RRB- .
67	Therefore , the context-based parser ranks the input received from the user using a sub-string matching algorithm that uses character-based unigram and <term id="33905" ann="1">bigram</term> counts -LRB- details are provided in the next section -RRB- .
68	When the <term id="39503" ann="2">dialogue manager</term> is expecting a certain type of input -LRB- examples : product names , yes\/no responses -RRB- from the user , the user response is processed by the context-based parser .
68	When the dialogue manager is expecting a certain type of input -LRB- examples : product <term id="382194" ann="1">names</term> , yes\/no responses -RRB- from the user , the user response is processed by the context-based parser .
68	When the dialogue manager is expecting a certain type of input -LRB- examples : product names , yes\/no responses -RRB- from the <term id="811" ann="1">user</term> , the user response is processed by the context-based parser .
68	When the dialogue manager is expecting a certain type of input -LRB- examples : product names , yes\/no responses -RRB- from the user , the <term id="811" ann="1">user</term> response is processed by the context-based parser .
68	When the dialogue manager is expecting a certain type of input -LRB- examples : product names , yes\/no responses -RRB- from the user , the user response is processed by the <term id="515811" ann="2">context-based parser</term> .
68	When the dialogue manager is expecting a certain type of input -LRB- examples : product names , yes\/no responses -RRB- from the user , the user response is processed by the context-based <term id="5506" ann="2">parser</term> .
89	Since the type of input is known , the <term id="515811" ann="2">context-based parser</term> uses a sub-string matching algorithm that uses character-based unigram and bigram counts to match the user input with the expectation of the dialogue manager .
89	Since the type of input is known , the context-based <term id="5506" ann="2">parser</term> uses a sub-string matching algorithm that uses character-based unigram and bigram counts to match the user input with the expectation of the dialogue manager .
89	Since the type of input is known , the context-based parser uses a <term id="459677" ann="2">sub-string matching</term> algorithm that uses character-based unigram and bigram counts to match the user input with the expectation of the dialogue manager .
89	Since the type of input is known , the context-based parser uses a sub-string <term id="1795" ann="2">matching</term> algorithm that uses character-based unigram and bigram counts to match the user input with the expectation of the dialogue manager .
89	Since the type of input is known , the context-based parser uses a sub-string <term id="18720" ann="2">matching algorithm</term> that uses character-based unigram and bigram counts to match the user input with the expectation of the dialogue manager .
89	Since the type of input is known , the context-based parser uses a sub-string matching <term id="453" ann="2">algorithm</term> that uses character-based unigram and bigram counts to match the user input with the expectation of the dialogue manager .
89	Since the type of input is known , the context-based parser uses a sub-string matching algorithm that uses character-based <term id="40448" ann="1">unigram</term> and bigram counts to match the user input with the expectation of the dialogue manager .
89	Since the type of input is known , the context-based parser uses a sub-string matching algorithm that uses character-based unigram and <term id="33905" ann="1">bigram</term> counts to match the user input with the expectation of the dialogue manager .
89	Since the type of input is known , the context-based parser uses a sub-string matching algorithm that uses character-based unigram and bigram counts to match the <term id="811" ann="1">user</term> input with the expectation of the dialogue manager .
89	Since the type of input is known , the context-based parser uses a sub-string matching algorithm that uses character-based unigram and bigram counts to match the user input with the expectation of the <term id="39503" ann="2">dialogue manager</term> .
93	Therefore , the <term id="459677" ann="2">sub-string matching</term> module takes as input a user utterance string along with a list of expected responses , and it ranks the list of expected responses based upon the user response .
93	Therefore , the sub-string <term id="1795" ann="2">matching</term> module takes as input a user utterance string along with a list of expected responses , and it ranks the list of expected responses based upon the user response .
93	Therefore , the sub-string matching module takes as input a <term id="811" ann="1">user</term> utterance string along with a list of expected responses , and it ranks the list of expected responses based upon the user response .
93	Therefore , the sub-string matching module takes as input a <term id="49149" ann="1">user utterance</term> string along with a list of expected responses , and it ranks the list of expected responses based upon the user response .
93	Therefore , the sub-string matching module takes as input a user <term id="5003" ann="1">utterance</term> string along with a list of expected responses , and it ranks the list of expected responses based upon the user response .
93	Therefore , the sub-string matching module takes as input a user utterance string along with a list of expected responses , and it ranks the list of expected responses based upon the <term id="811" ann="1">user</term> response .
131	Some customer service providers have started to take advantage of the recent advances in <term id="9254" ann="2">speech recognition</term> technology .
131	Some customer service providers have started to take advantage of the recent advances in <term id="120121" ann="2">speech recognition technology</term> .
131	Some customer service providers have started to take advantage of the recent advances in speech <term id="1413" ann="2">recognition</term> technology .
131	Some customer service providers have started to take advantage of the recent advances in speech <term id="120122" ann="2">recognition technology</term> .
131	Some customer service providers have started to take advantage of the recent advances in speech recognition <term id="1232" ann="1">technology</term> .
208	We conducted an experiment using the <term id="269736" ann="1">transfer rules</term> and transfer dictionary for a clerk with 23 unseen dialogues -LRB- 344 utterances -RRB- .
208	We conducted an experiment using the transfer rules and <term id="288605" ann="1">transfer dictionary</term> for a clerk with 23 unseen dialogues -LRB- 344 utterances -RRB- .
208	We conducted an experiment using the transfer rules and transfer <term id="1819" ann="1">dictionary</term> for a clerk with 23 unseen dialogues -LRB- 344 utterances -RRB- .
208	We conducted an experiment using the transfer rules and transfer dictionary for a clerk with 23 unseen <term id="241635" ann="1">dialogues</term> -LRB- 344 utterances -RRB- .
209	For example , if the microphone is for the clerk -LRB- the speaker is a clerk -RRB- , then the <term id="216374" ann="2">dialogue translation</term> system can select a more polite expression .
209	For example , if the microphone is for the clerk -LRB- the speaker is a clerk -RRB- , then the <term id="515918" ann="2">dialogue translation system</term> can select a more polite expression .
209	For example , if the microphone is for the clerk -LRB- the speaker is a clerk -RRB- , then the dialogue <term id="8804" ann="2">translation system</term> can select a more polite expression .
210	One reason is that TDMT does not know who or what the agent of the action in the <term id="5003" ann="1">utterance</term> is ; agents are also needed to select polite expressions .
216	We investigated Japanese outputs of a <term id="216374" ann="2">dialogue translation</term> system to see how many utterances should be polite expressions in a current translation system for travel arrangement .
216	We investigated Japanese outputs of a <term id="515918" ann="2">dialogue translation system</term> to see how many utterances should be polite expressions in a current translation system for travel arrangement .
216	We investigated Japanese outputs of a dialogue <term id="8804" ann="2">translation system</term> to see how many utterances should be polite expressions in a current translation system for travel arrangement .
216	We investigated Japanese outputs of a dialogue translation system to see how many utterances should be polite expressions in a current <term id="8804" ann="2">translation system</term> for travel arrangement .
217	The source example consists of <term id="13899" ann="1">words</term> that come from utterances referred to when a person creates transfer rules -LRB- we call such utterances closed utterances -RRB- .
217	The source example consists of words that come from utterances referred to when a person creates <term id="269736" ann="1">transfer rules</term> -LRB- we call such utterances closed utterances -RRB- .
219	In the next section , we describe how to incorporate the information on dialogue participants , such as roles and genders , into <term id="269736" ann="1">transfer rules</term> and dictionary entries in a dialogue translation system .
219	In the next section , we describe how to incorporate the information on dialogue participants , such as roles and genders , into transfer rules and <term id="1819" ann="1">dictionary</term> entries in a dialogue translation system .
219	In the next section , we describe how to incorporate the information on dialogue participants , such as roles and genders , into transfer rules and <term id="3445447" ann="1">dictionary entries</term> in a dialogue translation system .
219	In the next section , we describe how to incorporate the information on dialogue participants , such as roles and genders , into transfer rules and dictionary entries in a <term id="216374" ann="2">dialogue translation</term> system .
219	In the next section , we describe how to incorporate the information on dialogue participants , such as roles and genders , into transfer rules and dictionary entries in a <term id="515918" ann="2">dialogue translation system</term> .
219	In the next section , we describe how to incorporate the information on dialogue participants , such as roles and genders , into transfer rules and dictionary entries in a dialogue <term id="8804" ann="2">translation system</term> .
220	This paper describes a <term id="413" ann="1">method</term> of `` politeness '' selection according to a participant 's social role -LRB- a clerk or a customer -RRB- , which is easily obtained from the extra-linguistic environment .
221	We have been paying special attention to `` politeness , '' because a lack of politeness can interfere with a smooth <term id="4857" ann="1">conversation</term> between two participants , such as a clerk and a customer .
223	<term id="1017995" ann="1">translations</term> such as `` target word 11 '' are valid only in the source pattern ; that is , a source example might not always be translated into one of these target words .
225	It is easy for a <term id="216374" ann="2">dialogue translation</term> system to know which participant is the clerk and which is the customer from the interface -LRB- such as the wires to the microphones -RRB- .
225	It is easy for a <term id="515918" ann="2">dialogue translation system</term> to know which participant is the clerk and which is the customer from the interface -LRB- such as the wires to the microphones -RRB- .
225	It is easy for a dialogue <term id="8804" ann="2">translation system</term> to know which participant is the clerk and which is the customer from the interface -LRB- such as the wires to the microphones -RRB- .
226	We are considering ways to enable <term id="1248" ann="2">identification</term> of the agent of an action in an utterance and to expand the current framework to improve the level of politeness even more .
253	This result shows that a current <term id="8804" ann="2">translation system</term> is not enough to make a conversation smoothly .
253	This result shows that a current translation system is not enough to make a <term id="4857" ann="1">conversation</term> smoothly .
